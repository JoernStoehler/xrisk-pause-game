---
title: "What the Public Thinks About AI and the Implications for Governance"
author: "Brookings Institution"
year: 2024
source_url: "https://www.brookings.edu/articles/what-the-public-thinks-about-ai-and-the-implications-for-governance/"
source_format: html
downloaded: 2026-02-11
encrypted: false
notes: "Brookings analysis of public opinion on AI risks/benefits and implications for regulatory governance"
---

# Brookings: Public Opinion on AI and Governance Implications (2024)

## Overall Sentiment: Concern Outweighs Optimism

### Net Risk-Benefit Assessment

- **49% of Americans** (October 2023) believed AI risks outweigh benefits
- **34%** disagreed—saw benefits exceeding risks
- **52% of U.S. adults** (August 2023) felt more concerned than excited about increased AI use

### Emotional Responses

- **Nervousness**: 23-29% (dominant emotion)
- **Excitement**: 16-17% (much smaller share)

## Employment and Economic Concerns

### The Paradox of Personal Insulation

Americans demonstrate a striking disconnect between societal and personal risk perception:

- **28-31%** of British and American adults worry about their own work being automated
- **53-64%** of both populations expect AI to increase overall unemployment

**Key insight**: People acknowledge significant societal risk while believing themselves relatively protected. This suggests pessimism about labor market distribution rather than across-the-board job loss.

## Regulation Support—With Critical Implementation Gaps

### Strong Demand for Oversight

- **71% globally** (October 2022) disagreed that AI regulation is unnecessary
- **Strong majorities** in both U.S. and U.K. support regulation

### Deep Distrust of Existing Institutions

The public demands regulation but lacks confidence in implementers:

- **82% of U.S. voters** (July 2023) distrust tech executives for self-regulation
- **68% of U.K. adults** lacked confidence in government's ability to regulate effectively
- **62% of U.S. public** have not too much or no confidence in U.S. government regulation
- **53% of AI experts** also express similar skepticism about government capacity

### Technical Knowledge Gap

- **63% of U.S.** and **66% of U.K.** citizens believe regulators lack adequate technical understanding of AI

This represents a critical barrier to public trust in regulation—people believe regulators cannot understand what they're regulating.

## Preferred Governance Models

### Multi-Stakeholder Approaches Win Support

Majorities favor approaches combining multiple oversight mechanisms:

- **Multi-stakeholder governance**: Strong support
- **International cooperation**: Preferred over unilateral national approaches
- **Independent experts**: Preferred over either government or industry alone

### Why Multi-Stakeholder?

Public appears to believe that no single institution (government, industry, or academia) can be trusted alone to oversee AI development safely.

## Specific Application Concerns

### High-Stakes Decision-Making

Americans express particular concern about AI in:
- **Hiring decisions**: 85%
- **Autonomous vehicles**: 83%
- **Medical recommendations**: 80%

### Information Integrity

- **Political influence**: 58% concerned
- **News media coverage**: 53% concerned
- **Misinformation amplification**: Growing concern

## Political Dimension

### Bipartisan Agreement on Concerns

Rare bipartisan consensus exists on AI risks:
- Both Republicans and Democrats recognize job displacement concerns
- Both worry about national security impacts
- Both concerned about social connection decline
- Both worried about misinformation amplification

### Bipartisan Disagreement on Solutions

While concerns are shared, proposals for addressing them divide along partisan lines:
- Democrats favor stronger government regulation
- Republicans favor market-based or lighter-touch approaches
- Disagreement on international cooperation necessity

## Longitudinal Trend Data

### Growing Concerns Over Time

- Concern about AI has increased from 2021 to 2024
- **37%** more concerned than excited (2021) → **50%** (2024)
- Risk perception has grown more salient

### Changing Benefit Perception

- Benefits acknowledgment has remained relatively stable
- But overall net sentiment has shifted more negative

## Knowledge and Demographic Factors

### Information Gaps Across Population

- **64%** report being at least somewhat knowledgeable about AI
- **9%** claim comprehensive knowledge
- Significant gaps for older adults and women
- Knowledge correlates with trust levels

### Age and Gender Differences

- **Younger demographics**: More familiarity and generally lower concern
- **Older adults**: Lower knowledge correlates with higher concern
- **Gender gap**: Men report 72% knowledge vs. women 57%

## Policy Implementation Challenges

### Evidence-Based Policymaking Barriers

Researchers identified critical gaps limiting governance effectiveness:

- **Absence of comprehensive longitudinal tracking** in the U.S.
- Limits ability to measure policy impacts
- Prevents evidence-based refinement of regulatory approaches
- Complicates trend analysis for policymakers

## Public Trust in Decision-Makers

### Confidence Rankings (Future of Life Institute)

- **International scientific organizations**: Highest trust
- **University and nonprofit researchers**: 69% trust for safety guidance
- **AI company leadership**: Significantly lower confidence
- **59%** have little or no confidence in U.S. companies developing AI responsibly

## Takeaways for AI Policy and Governance

1. **Regulation Demanded But Not Trusted**: Public wants oversight but doubts implementers' capacity
2. **Multi-Stakeholder Preference**: No single institution trusted alone; public wants checks and balances
3. **Technical Competency Gap**: Regulators perceived as ill-equipped to understand AI systems
4. **Application-Specific Concerns**: Risk perception varies sharply by use case
5. **Disconnected Optimism**: People pessimistic about general economy but believe themselves protected
6. **Growing, Not Shrinking**: Concerns have increased over time, not stabilized
7. **Shared Concerns, Partisan Solutions**: Bipartisan recognition of problems but disagreement on solutions

## Implications for the AI CEO Game

- Public will pressure government to regulate AI more heavily
- Media coverage will highlight regulation failures and safety incidents
- Political credibility depends on transparency and independent oversight
- International cooperation proposals will split publically along partisan lines
- Trust in business leadership is extremely low—transparency and accountability mechanisms are essential
