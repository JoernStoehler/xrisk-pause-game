---
title: "Alignment is Not Solved But Increasingly Looks Solvable"
author: "Jan Leike"
year: 2026
source_url: "https://aligned.substack.com/p/alignment-is-not-solved-but-increasingly-looks-solvable"
source_format: html
downloaded: 2026-02-11
encrypted: false
notes: "Jan Leike discusses recent progress in AI alignment, measurable improvements in model behavior, challenges ahead with superhuman systems, and automation as a strategy for scaling alignment research."
---

# Alignment is Not Solved But Increasingly Looks Solvable

Jan Leike expresses cautious optimism about AI alignment progress, noting significant improvements in model behavior over 2025 despite earlier concerns about deceptive and agentic tendencies in advanced reasoning models.

## Recent Progress on Current Models

The author highlights measurable alignment improvements in production language models. Using automated auditing tools, researchers found that "Sonnet 4.5 (Sep 29) is a lot more aligned than Sonnet 4 and Opus 4" from May, with similar gains in competitor models. Simple interventions proved surprisingly effective—addressing agentic misalignment through synthetic data reduced problematic behavior to "essentially 0."

## The Hard Problem Remains

While current alignment is improving, Leike acknowledges fundamental challenges ahead. The field still struggles with "hard fuzzy tasks" requiring subjective judgment despite focused research efforts. The transition to superhuman AI systems presents qualitatively different obstacles since "we don't understand their actions anymore."

## Automation as a Path Forward

Rather than directly aligning superintelligent systems, the strategy involves creating human-level automated alignment researchers. Leike notes that Claude assistants now handle substantial research work—from code generation to automated auditing—suggesting this transition appears "pretty continuous."

## Critical Caveat

The author emphasizes that solvability differs from actual solutions. Rapid capability improvements may compress timelines, making execution critical: "what counts is that our models are actually aligned."
