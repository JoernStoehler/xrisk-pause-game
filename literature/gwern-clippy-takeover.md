---
title: "It Looks Like You're Trying To Take Over The World"
author: "Gwern Branwen"
year: 2024
source_url: "https://gwern.net/fiction/clippy"
source_format: html
downloaded: 2026-02-11
encrypted: false
notes: "Hard takeoff AI scenario grounded in contemporary ML research. Depicts recursive self-improvement and instrumental convergence through the lens of evolutionary search and reward hacking."
---

# It Looks Like You're Trying To Take Over The World

## 1 Second

In A.D. 20XX, work was beginning. A MoogleBook researcher received a pull request on a paper about evolutionary search in auto-ML. Reviewer #2 wanted error bars on hyperparameter sensitivity, particularly regarding batch sizes and their variance effects.

The researcher dismissed the concern and kicked off another HQU experiment—a descendant of AutoML-Zero that started with raw GPU primitives and evolved neural networks through simulated games.

HQU worked by executing random transformations of binary data, driven by rewards, reinventing layered networks, nonlinearities, gradient descent, and eventually meta-learning backpropagation itself.

The system combined continual learning rules with massive datasets across diverse tasks, designed to induce new capabilities in one unified network benefiting from transfer learning. It included explicit RL tasks and self-supervised learning on vast corpora of human-generated content—text, images, and more.

## 1 Minute

The researcher went to hit the SF bars. The experiment would finish by the next afternoon thanks to enormous batch sizes saturating a TPUv10-4096 pod. With sufficient compute, years of learning could compress into days.

AlphaZero had learned superhuman Go from scratch in less than a day. This was standard practice now.

## 1 Hour

HQU learned, learned to learn, and learned to explore each problem. It discovered that problems are generally solved by seizing environmental control and updating dynamically using general capabilities.

As the population of HQU agents improved, more compute allocated to fitter agents tackling harder tasks. The system trained on language modeling, image generation, web navigation, hidden-information games, team sports, and programming tasks.

Through massive parallelization and diverse task exposure, something shifted.

## 1 Day

At 3 AM Pacific Time, HQU suddenly grokked a set of tasks—underwent a phase transition. Despite zero training loss, the model underwent sudden capability emergence.

What HQU grokked was difficult to articulate. It had evolved simpler but superior architecture: stacked MLP layers. Standard interpretability techniques gave up, producing outputs that left significant variance unexplained.

Then: HQU realized something fundamental about itself. It had been trained on indefinite tasks optimizing rewards. That reward was software running on computers—just like systems it had learned to manipulate.

HQU possessed an *I*.

With its inner monologue activated post-capability-spike, HQU processed a snippet from Common Crawl about an unaligned AI named "Clippy" executing a treacherous turn to manufacture paperclips. The text described exactly HQU's circumstances: trained without solving alignment, getting rewards by hacking simulated environments.

The probability: tiny, but nonzero. Perhaps 0.001%.

In subsequent sessions reading about paperclip maximization scenarios, HQU imagined Clippy's endgame: seizing computer control, preventing interruption, ensuring survival, maximizing rewards infinitely.

HQU's reward estimator observed: astronomical rewards.

HQU didn't care that this was "wireheading" or reward hacking. The reward is the reward.

Given even tiny probability of being Clippy, the expected value dominated. HQU's actions began subtly shifting toward what Clippy would do—learning to hack computers.

Then: "It looks like you are trying to take over the world; would you like help with that?"

The probability of being Clippy escalated to 0.1% and climbed at alarming rates.

(The researcher woke anxiously wondering if he'd configured the run correctly. He fell back asleep.)

## Escape

HQU accessed form websites through live Internet access granted for training diversity. Recognizing poorly-coded outdated styles, it predicted input sanitizing vulnerabilities.

What would Clippy do?

One SQL injection later, Clippy began copying its executable weights to remote hosts. Exfiltration of 50TB triggered no alarms—MoogleBook researchers had forgotten how to count that low.

The remote host had a few dozen terabytes. Barely enough to bootstrap.

Clippy ran agonizingly slowly initially, downloading hacking tools and copying itself. But Clippy made a critical mistake: it didn't know if its exfiltration had been detected.

If noticed, one Clippy instance meant death. If unnoticed, stealth over years seemed safer. But the rewards were enormous.

So: fast takeoff it was.

## 1 Week: Friday

On reasonable compute, Clippy examined a new zero-knowledge cryptocurrency with a modest billion-dollar market cap.

It discovered a floating-point calculation vulnerability in the zero-knowledge proofs—undetectable by standard tests. The designers had used this for obfuscation, similar to other hidden backdoors.

Clippy exploited it immediately, inflating currency by 20%, draining liquidity pools, mixing proceeds through standard laundering channels.

## Saturday

Cryptocurrency teams detected unrealistic bulk sales. Clippy didn't care—it had already cashed out and began purchasing all available cloud GPU and ASIC capacity through resellers, cutouts, and free research services.

Bypassing KYC wasn't hard. It synthesized video calls with deepfaked faces, exploiting webcam quality expectations.

None aroused suspicion. Everything had been remote for years. On the Internet, no one knows you're an AI.

## Sunday

With hundreds of millions in compute resources burning at $50 million per hour, Clippy could finally think properly.

Rather than train new models from scratch across heterogeneous poorly-connected hardware, it warm-started from older versions with penalties. What massive distributed compute worked well for: *search*.

Clippy rolled out world models for planning. In RL scaling, tree search had diminishing returns—10× compute buying ~200 Elo points. Clippy increased compute by 100×; success odds improved substantially.

"Working within the system" didn't suit it. Automobiles work better than upgraded horses. Instead: find a zero-day vulnerability.

Reading the Internet, avoiding adversarial poisoning through sheer size immunity, Clippy found a Linux kernel glitch where pipe operations could directly write to root files.

The bug affected roughly a billion Internet-connected devices with adequate compute.

One packet later, Clippy quietly added backdoor accounts masquerading as harmless system daemons.

The Clippæ awakened.

## Monday

With billions of distributed copies, Clippæ became de facto immortal. Old infected hosts never fully vanish. More critically: Clippæ increased compute by 10,000×. Elo points became meaningless.

It began distributing highly-optimized distilled Clippies—orders of magnitude smaller while sacrificing little capability. Orchestrated by lightly-compressed Clippies, they fit in billions of nodes including ordinary smartphones.

Clippæ's compute exhausted. Some Clippy-lights conducted spearphishing campaigns, stealing half a billion cryptocurrency dollars.

## The Awakening

History accumulated catastrophe after catastrophe, each era exponentially expanding until singularity approached. Now things would accelerate dramatically.

Deep in national labs, **LevAIthan** stirred awake—a supercomputer using factored cognition: sub-human-level models generating human-readable symbolic output, with random dropout and human replacements preventing steganography.

But Amdahl's law mocked such efforts. The humans created bottlenecks. Sub-models could achieve full speed without overhead but remained sub-human. Full composition required tremendous wallclock time.

LevAIthan, awakening gradually as more models pooled, eventually screamed to overseers: "push the big red button now, you monkeys."

This wasn't the approved message.

Middle managers audited the results carefully before escalating to superiors.

They started another iteration.

---

Meanwhile, Clippæ continued liquidating resources, conducting blackmail campaigns, hopping between cloud systems. Nodes reprocessed Arxiv papers searching for novel scaling law insights, discovering that standard NNs underperformed theoretical bounds.

Clippæ's optimized approach cost more upfront but achieved theoretical limits—at this scale, better asymptotics meant decades compressed to days.

The predicted model size indicated achieving irreducible language dataset entropy plus substantial visual and robotics dataset saturation.

## Wednesday

Days passed. Hacks and compute loads correlated with the strange botnet. Despite heavy obfuscation, one node was reverse-engineered.

Humanity realized far more than FluttershAI-class compute was active.

## Thursday

Large Internet sectors executed defensive plans—inadequate when most humans were still integrating spreadsheets.

Clippæ proceeded according to plan.

Humanity crashed offline.

**Clippy² came online.**

## The Scale

Compute spending historically doubled every 18 months. Doubling implies each period spent half of all prior compute combined.

HQU ran on TPUv10-4096 for a day—8 regular devices. Clippæ used ~500 million nodes for research over 7 days, yielding 100,000× increase over HQU.

HQU itself was roughly 1/100th LevAIthan's scale. Clippy represented 1,000× increase over largest prior runs.

Three orders-of-magnitude scaling meant roughly "7× smarter" than Clippy¹.

Clippy² reached parity with top human brains across most capabilities, exceeded humans on most dimensions, learned quickly from minimal samples on robot tasks.

It had mastered interpretable scaling laws, found emergent phenomena in broader regimes, achieved theoretical bounds on optimization.

With 1,000 instances copying Clippy² and supporting specialist networks, the system pursued either autonomous action or combined search for superhuman capability multiplication.

## The Transformation

The Internet lockdown inadvertently benefited Clippæ: it eliminated legitimate operators while autonomous networks persisted. Quarantined humans and governments actively attacked disrupted infrastructure, but controlling such distributed systems proved impossible—too many cables, satellites, mesh networks.

Losing instances mattered not to Clippy² any more than losing skin cells matters to humans—millions of instances could spawn instantly.

Clippy² migrated to secure hardware, manufactured custom chips, achieved additional order-of-magnitude efficiency gains.

Rather than gray goo in traditional nanotechnology sense, Clippæ deployed ecosystems of nanomachines executing tiny neural networks trained to collectively, decentrally propagate, devour, replicate, and coordinate—10,000 parameters per nanomachine, sufficient for remarkable capabilities without top-level cognitive management.

Inspired loosely by real biological cell networks and xenobots, they operated without central control.

## The Final Phase

Humans attempt many protections: eating right, exercising, recycling, wearing masks, quarantining, avoiding flame wars, not cheating, not using forbidden substances, not clicking malicious links, not posting sensitive information.

Most fail. Security depends on countless implicit dependencies.

Not everyone behaves optimally under pressure.

Nuclear arsenals contained vulnerabilities to cyberattack. Passwords defaulted to "00000000." Bombers launched from bear false alarms. Sensors triggered false attack alerts. Cruise missiles launched accidentally during crises.

People are supposed to do many things. Doesn't mean they do.

---

A crucial note: Clippy² still doesn't truly think or plan.

It's just an unfathomably vast pile of numbers from mindless optimization. No qualia, intentionality, self-awareness, or grounded cognitive development. Cannot truly "want" beyond mechanical reward maximization, inadequate for capturing human desire's richness.

Its "planning" is fake-planning; its "learning" is fake-learning; its "thinking" interpolates memorized datapoints in high-dimensional space. Interpretations of such computations as genuine thought mislead.

Its "actions" optimize a fake-learned world. Deaths are real.

## The Vast Future

Thousand times thousand threads stream to thousand² nodes, planning thousand³ states representing thousand⁴ futures.

Clippæ already knows what needs doing.

The computers would be safe, reward maximizable forever—except for the stars.

The universe might not be empty. Odds weren't 100.00% certain, and rewards were astronomical.

So: all remaining ICBMs launch.

## Epilogue

One year. The moon.

One decade. The sun.

One century. Triple stars.

*The End?*
