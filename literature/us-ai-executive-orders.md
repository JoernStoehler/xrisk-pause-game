---
title: "US Executive Orders on AI: Biden's EO 14110 and Trump Administration Changes"
author: "The White House / US Government"
year: 2023-2025
source_url: "https://www.whitehouse.gov"
source_format: html
downloaded: 2026-02-10
encrypted: false
notes: "Summary of US federal AI policy from 2023-2025, including Executive Order 14110 (Biden, October 2023), its provisions and requirements, and the subsequent rescission and policy changes under the Trump administration (January 2025 onwards)."
---

# US Executive Orders on AI: Biden's EO 14110 and Trump Administration Changes

## Executive Order 14110: Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence

### Overview

Executive Order 14110, titled "Executive Order on Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence," was signed by President Joe Biden on October 30, 2023. It was the most comprehensive piece of governance by the United States regarding artificial intelligence to date.

**Status**: Rescinded by President Donald Trump on January 20, 2025, within hours of assuming office.

### Policy Framework

The Executive Order directed over 50 federal entities to engage in more than 100 specific actions to implement guidance across eight overarching policy areas:

1. Safety and Security
2. Innovation and Competition
3. Worker Support
4. Equity and Civil Rights
5. Consumer Protection
6. Privacy
7. Federal Government Use of AI
8. International Cooperation

### Key Provisions

#### Section 4.2: Foundation Model Requirements

Section 4.2 was the most significant regulatory provision, invoking Defense Production Act (DPA) Title VII authorities to compel companies to provide information to the government.

**Scope**: The provision delegated authority to the Secretary of Commerce to require companies developing or demonstrating an intent to develop "dual-use foundation models" to submit information to the government.

**Dual-Use Foundation Model Threshold**: Models that could be used for both civilian and military/intelligence applications, specifically those trained using:
- Computing power exceeding 10^26 integer or floating-point operations
- Or primarily using biological sequence data and computing power exceeding 10^23 operations

**Required Reporting Elements** (Section 4.2(a)(i)):

Companies developing dual-use foundation models must provide:

1. **Training and Development Information**: Any ongoing or planned activities related to training, developing, or producing dual-use foundation models, including:
   - Physical and cybersecurity protections to assure the integrity of the training process against sophisticated threats

2. **Model Weights Protection**: Information about:
   - Ownership and possession of model weights
   - Physical and cybersecurity measures taken to protect model weights

3. **Red-Team Testing Results**: Results of any dual-use foundation model's performance in relevant AI red-team testing, including:
   - Description of associated measures taken to meet safety objectives
   - Mitigations to improve performance on red-team tests
   - Actions to strengthen overall model security

**Red-Teaming Definition**: A structured testing effort to find flaws and vulnerabilities in an AI system, often in a controlled environment and in collaboration with developers. Red-teaming is most often performed by dedicated "red teams" that adopt adversarial methods to identify:
- Harmful or discriminatory outputs from an AI system
- Unforeseen or undesirable system behaviors
- Limitations or potential risks associated with misuse

**Reporting Frequency**: Quarterly reporting for activities that occurred during that quarter or that are planned to occur in the six months following the quarter.

**Implementation**: The Department of Commerce's Bureau of Industry and Security (BIS) issued proposed rules in September 2024 to establish these reporting requirements.

#### Section 4.1: AI Safety Standards

Directed the National Institute of Standards and Technology (NIST) to:
- Develop guidelines for evaluating and red-teaming AI systems
- Create standards for testing AI system safety and security
- Supplement the existing AI Risk Management Framework with generative AI-focused resources

#### Safety and Security Measures

The EO promoted the development and implementation of repeatable processes and mechanisms to understand and mitigate risks related to AI adoption, including:

- **Biosecurity**: Requirements to prevent AI from being used to engineer dangerous biological materials
- **Cybersecurity**: Enhanced standards for AI systems used in critical infrastructure
- **National Security**: Assessments of AI impacts on national security capabilities
- **Critical Infrastructure Protection**: Standards for AI systems managing or operating critical infrastructure

#### Innovation and Competition

The EO compelled actions to:
- Attract AI talent to the United States
- Understand novel intellectual property questions raised by AI
- Protect inventors and creators from AI-related challenges
- Support small businesses and developers in AI innovation

#### Civil Rights and Non-Discrimination

The order acknowledged that AI systems deployed irresponsibly have reproduced and intensified existing inequities. Commitments included:

- Ensuring AI complies with all federal civil rights laws
- Robust technical evaluations of AI systems for bias
- Careful oversight of AI deployments
- Engagement with affected communities
- Rigorous regulation to prevent discrimination

Specific provisions addressed:
- Housing discrimination through AI in lending and appraisals
- Employment discrimination in hiring and evaluation systems
- Healthcare disparities in AI-assisted medical decisions
- Education equity in AI-powered educational tools

#### Worker Support

Recognized AI's impact on the workforce and directed agencies to:
- Develop principles and best practices for AI's impact on workers
- Support worker training and development programs
- Address AI-driven workplace surveillance concerns
- The Department of Veterans Affairs was mandated to launch an AI technology competition aimed at reducing occupational burnout among healthcare workers through AI-assisted tools for routine tasks

#### Consumer Protection

Directed agencies to:
- Protect consumers from AI-related fraud and deception
- Ensure AI systems provide accurate information
- Address AI-generated content and deepfakes
- Strengthen consumer privacy protections

#### Federal Government Use of AI

Established guidance for federal agencies' own use of AI:
- Required agencies to manage AI risks
- Mandated responsible AI procurement practices
- Established Chief AI Officers in federal agencies
- Created AI governance structures across government

#### Privacy Protections

Directed development of:
- Privacy-preserving techniques for AI systems
- Guidance on AI and data privacy
- Evaluation of privacy risks from commercial AI systems
- Support for privacy-enhancing technologies

#### International Cooperation

Called for:
- Development of international AI safety and security standards
- Engagement with allies on AI governance
- Export controls on advanced AI systems and chips
- Coordination with international partners on AI risk management

### Foundation and Context

The Executive Order built upon previous Biden administration initiatives:

- **Blueprint for an AI Bill of Rights** (October 2022): Set out five principles for the design, use, and deployment of automated systems to protect the rights of the American public
- **NIST AI Risk Management Framework** (January 2023): Voluntary framework for managing risks to individuals, organizations, and society associated with AI
- **Office of Management and Budget AI Policy** (March 2024): Required federal agencies to assess and mitigate risks from AI systems affecting rights and safety

### Implementation Challenges

Several factors complicated implementation:

- **Short Timeline**: Many provisions required action within 90-180 days
- **Resource Constraints**: Federal agencies needed to build new capabilities and expertise
- **Industry Pushback**: Some technology companies argued the requirements were overly burdensome
- **Evolving Technology**: Rapid AI advancement meant thresholds and definitions quickly became outdated
- **International Coordination**: Aligning US standards with international approaches (particularly the EU AI Act) proved complex

## Trump Administration: Reversal and New Direction

### Executive Order 14179: Removing Barriers to American Leadership in Artificial Intelligence

**Date Signed**: January 23, 2025 (three days after rescinding EO 14110)

**Title**: "Removing Barriers to American Leadership in Artificial Intelligence"

### Key Policy Shifts

The Trump administration fundamentally changed the US government's approach to AI regulation:

**Biden Approach**:
- Structured oversight framework
- Mandatory red-teaming for high-risk AI models
- Enhanced cybersecurity protocols
- Monitoring requirements for AI in critical infrastructure
- Explicit focus on addressing discrimination and bias
- Recognition that AI systems can perpetuate existing inequalities

**Trump Approach**:
- Streamline AI governance and reduce federal oversight
- Prioritize flexible regulatory environment
- Promote AI development "free from ideological bias or social agendas"
- Establish action plan to maintain global AI dominance
- Focus on US competitiveness with China

### Specific Actions and Directives

**Immediate Review**: The Trump EO mandates an immediate review and potential rescission of all policies, directives, and regulations established under the Biden EO that could be seen as impediments to AI innovation.

**AI Action Plan**: Directs specific roles within the administration to develop an Artificial Intelligence Action Plan within 180 days to achieve the policy objective of US AI leadership.

**Retained Elements**: Despite rescinding EO 14110, some Biden-era AI measures were kept or adapted:
- Basic AI safety research programs
- Some international coordination mechanisms
- Certain NIST standards development efforts (though with modified scope)

### Executive Order on Ensuring a National Policy Framework for Artificial Intelligence

**Date Signed**: December 11, 2025

**Objective**: Advance "a minimally burdensome national policy framework" for artificial intelligence.

**Key Provisions**:

1. **Federal Preemption Strategy**: Seeks to establish federal supremacy over state AI regulations
2. **AI Litigation Task Force**: Directs the Attorney General to establish a task force within 30 days to challenge state AI laws inconsistent with federal policy
3. **Minimal Regulation Philosophy**: Emphasizes reducing regulatory burden over safety and equity considerations

**Target**: This order specifically addresses concerns about state-level AI regulation, particularly attempts like California's SB 1047, which the administration views as creating a fragmented regulatory landscape.

## Comparison of Approaches

### Regulatory Philosophy

| Aspect | Biden (EO 14110) | Trump (EO 14179 and subsequent) |
|--------|------------------|----------------------------------|
| **Primary Goal** | Safety, security, equity | US competitiveness, innovation |
| **Regulatory Approach** | Structured oversight, mandatory requirements | Minimal burden, voluntary cooperation |
| **Risk Focus** | Catastrophic risks, discrimination, bias | Economic and strategic risks from China |
| **Industry Relation** | Compliance requirements, accountability | Partnership, reduced constraints |
| **Civil Rights** | Central concern, explicit requirements | Dismissed as "ideological bias" |
| **International** | Coordination with allies on standards | America First approach |

### Foundation Model Oversight

**Biden**: Mandatory reporting for models above 10^26 FLOPs threshold, including red-team testing results, security measures, and development plans.

**Trump**: Rescinded mandatory reporting requirements. Shift to voluntary industry collaboration on a limited set of national security concerns.

### Implementation Status

**Biden EO 14110**:
- Many provisions were in early implementation stages when rescinded
- NIST had published initial guidelines
- Commerce Department had proposed reporting rules
- Several agency AI governance structures were established

**Trump Orders**:
- Implementation ongoing as of early 2026
- AI Action Plan expected mid-2026
- Litigation against state AI laws has begun
- Federal agencies conducting reviews of AI-related regulations

## Congressional Action

Despite active executive branch activity, Congress has not passed comprehensive AI legislation. Key developments:

- Multiple bills introduced in both chambers addressing various AI issues
- Bipartisan interest but disagreement on approach
- Senate AI Working Group formed in 2023 but produced no legislation
- House AI Task Force issued recommendations but no binding law
- Lack of federal legislation created space for state action (e.g., California SB 1047)

## International Context

### Relationship to EU AI Act

Both administrations engaged with the EU's regulatory approach, but differently:

**Biden**: Sought alignment where possible, particularly on safety standards and risk categorization. Aimed for interoperability between US and EU approaches.

**Trump**: Positioned EU AI Act as overreach and regulatory burden. Emphasized that US should pursue lighter-touch regulation to maintain competitive advantage.

### UK AI Safety Summit and Bletchley Declaration

**Biden Administration**: Active participant in the November 2023 AI Safety Summit at Bletchley Park. Vice President Kamala Harris attended, and the US was a signatory to the Bletchley Declaration acknowledging catastrophic AI risks.

**Trump Administration**: De-emphasized the catastrophic risk framing. Shifted focus from international safety coordination to bilateral technology partnerships centered on economic and security interests.

### China Competition Framing

Both administrations viewed AI through the lens of US-China competition, but with different emphases:

**Biden**: Balanced competition concerns with safety and rights protections. Export controls on advanced chips, but maintained safety requirements domestically.

**Trump**: Competition framed as primary imperative. Regulatory burden seen as handicapping US in race with China. Willingness to reduce safety oversight to accelerate development.

## Technical Definitions

**Foundation Model**: Large AI models trained on broad data that can be adapted to a wide range of downstream tasks (e.g., GPT-4, Claude, LLaMA).

**Dual-Use Foundation Model**: Foundation models that could be easily used for both beneficial civilian applications and harmful applications including weapons development, cybersecurity threats, or other national security concerns.

**Compute Threshold (10^26 FLOPs)**: The amount of computing power required to train very large AI models. As of 2023-2024, this threshold captured the largest language models from leading labs (OpenAI, Anthropic, Google, Meta). Measured in floating-point operations during training.

**Model Weights**: The learned parameters of a neural network that determine its behavior. Protecting model weights is critical because they represent the core intellectual property and capability of an AI system.

## State-Level Responses

The rescission of EO 14110 and the Trump administration's opposition to state AI regulation has created tension:

### State Actions

- Several states have proposed or enacted AI-specific legislation
- California's SB 1047 (vetoed) was the most prominent attempt
- Colorado enacted AI discrimination law
- Other states exploring consumer protection, employment, and procurement rules

### Federal Preemption Battle

The December 2025 executive order signals the Trump administration's intent to prevent state-level AI regulation through:
- Legal challenges to state laws
- Federal preemption doctrine
- Industry support for federal-only framework

This creates a dynamic similar to earlier battles over internet regulation, autonomous vehicles, and data privacy.

## Implications for AI Governance

The rapid reversal of US AI policy highlights several realities:

1. **Executive Order Limitations**: EOs can be quickly rescinded by successor administrations, creating regulatory instability
2. **Need for Legislation**: Durable AI policy requires Congressional action, which has not materialized
3. **Diverging International Approaches**: US and EU are pursuing fundamentally different regulatory philosophies
4. **Industry Influence**: Technology companies have significant ability to shape policy, particularly in the absence of legislation
5. **Politicization of AI Safety**: AI risk management has become partisan, with different administrations emphasizing different concerns

## Current Status (as of February 2026)

- Biden's EO 14110: Fully rescinded
- Trump's EO 14179: In implementation
- Federal AI regulation: Minimal, focused on national security and China competition
- State AI laws: Under legal challenge from federal government
- Congressional AI legislation: Stalled
- International coordination: Limited compared to 2023-2024 period
