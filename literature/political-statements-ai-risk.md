---
title: "Key Political Statements on AI Risk: Heads of State, Officials, and International Declarations (2023-2025)"
author: "Various government officials and international bodies"
year: 2023-2025
source_url: "https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration"
source_format: html
downloaded: 2026-02-10
encrypted: false
notes: "Compilation of significant public statements from heads of state, AI ministers, international bodies, and key politicians about existential and catastrophic AI risk. Focuses on how governments are framing and responding to AI risk in official contexts (2023-2025)."
---

# Key Political Statements on AI Risk: Heads of State, Officials, and International Declarations (2023-2025)

## The Bletchley Declaration (November 2023)

### Overview

The AI Safety Summit was an international conference discussing the safety and regulation of artificial intelligence, held at Bletchley Park, Milton Keynes, United Kingdom, on November 1-2, 2023. It was the **first ever global summit on artificial intelligence**.

**Host**: United Kingdom Government under Prime Minister Rishi Sunak

**Signatories**: 28 countries plus the European Union, including:
- United States
- United Kingdom
- China
- European Union member states
- Canada
- Australia
- Japan
- South Korea
- India
- Brazil
- Saudi Arabia
- United Arab Emirates
- And others

### The Declaration Text: Key Excerpts

**Preamble on AI Opportunities**:
> "AI presents enormous global opportunities: it has the potential to transform and enhance human wellbeing, peace and prosperity."

**Recognition of Risks**:
> "There is potential for serious, even catastrophic, harm, either deliberate or unintentional, stemming from the most significant capabilities of these AI models."

**Specific Domains of Concern**:
> "We are especially concerned by such risks in domains such as cybersecurity and biotechnology, as well as where frontier AI systems may amplify risks such as disinformation."

**Types of Risks Identified**:
> "Substantial risks may arise from potential intentional misuse or unintended issues of control relating to alignment with human intent."

**Commitment to Cooperation**:
> "We resolve to work together in an inclusive manner to ensure human-centric, trustworthy and responsible AI that is safe, and supports the good of all through existing international fora and other relevant initiatives, to promote cooperation to address the broad range of risks posed by AI."

### Significance

**First International Consensus**: The Bletchley Declaration represents the first time major world powers - including geopolitical rivals like the US and China - agreed on a statement acknowledging catastrophic AI risks.

**Frontier AI Focus**: Specifically addressed the most advanced AI systems, not general AI technology. This narrowed scope was critical to achieving consensus.

**Non-Binding but Influential**: While the Declaration itself creates no legal obligations, it established political momentum and framed AI risk as a legitimate concern for heads of state.

### Participating Officials

Key government representatives included:
- **Vice President Kamala Harris** (United States)
- **Prime Minister Rishi Sunak** (United Kingdom)
- **President of the European Commission Ursula von der Leyen** (European Union)
- **Minister Wu Zhaohui** (China's Science and Technology Minister)
- And ministerial-level representatives from other signatory nations

### UK AI Safety Institute Announcement

The summit also saw the announcement of the UK AI Safety Institute (AISI), a government body dedicated to:
- Evaluating advanced AI models for safety
- Conducting research on AI risks
- Developing testing methodologies
- Coordinating internationally on AI safety research

Similar institutes were subsequently announced by the US and other countries.

## UK Government Statements (2023-2024)

### Prime Minister Rishi Sunak

**November 2023 - Opening Remarks at AI Safety Summit**:

Rishi Sunak positioned the UK as a leader in AI safety, stating that addressing AI risk was a moral responsibility of governments. He emphasized:
- The need to understand and mitigate risks before they materialize
- Balance between safety and innovation
- The UK's unique position to convene global actors (including China)

**"Fireside Chat" with Elon Musk (November 2023)**:

In an unusual public discussion following the summit, PM Sunak and Elon Musk discussed AI risks. Sunak acknowledged concerns about AI potentially becoming "the most disruptive force in history" and emphasized government's role in providing "guardrails."

### UK Government's Approach: Evolution

**Initial Approach (2023)**: Light-touch regulation, principles-based framework, emphasis on innovation

**AI Safety Institute (2023-2024)**: Shift toward more active government role in testing and evaluating frontier AI models, while maintaining non-statutory approach

**Context**: The UK sought to position itself as a global leader in AI safety while also attracting AI companies to locate in the UK. This created tension between safety concerns and economic development goals.

## United States Government Statements

### Biden Administration (2023-2024)

**President Joe Biden - Executive Order Signing (October 2023)**:

When signing Executive Order 14110, President Biden stated:
> "AI is all around us... To realize the promise of AI and avoid the risk, we need to govern this technology."

He emphasized both the opportunities and serious risks, including:
- AI-generated deepfakes and disinformation
- Discrimination and bias
- National security threats
- Need to stay ahead of China while managing risks

**Vice President Kamala Harris - AI Safety Summit (November 2023)**:

VP Harris represented the US at the Bletchley Summit, where she stated:
> "History has shown, in the absence of regulation and strong government oversight, some technology companies choose to prioritize profit over the wellbeing of their customers, the safety of our communities, and the stability of our democracies."

She emphasized the US commitment to both innovation and safety, and the need for international cooperation.

**Vice President Harris - AI Declarations (2023-2024)**:

Harris took an active role in AI policy, giving multiple speeches emphasizing:
- Civil rights implications of AI
- Need for accountability
- Importance of diverse perspectives in AI development
- Government responsibility to protect citizens

### US State Department Report (2024)

A report commissioned by the US State Department in 2024 (authored by external experts) warned that **human extinction was a worst-case outcome of AI development**. This represented a significant acknowledgment by a government agency of existential risk from AI.

Key points from the report:
- Advanced AI systems pose risks of loss of control
- Catastrophic outcomes are possible if development proceeds without adequate safeguards
- International coordination is essential
- Current governance mechanisms are insufficient

### Trump Administration Pivot (2025)

**President Donald Trump - Rescinding EO 14110 (January 2025)**:

The Trump administration did not issue detailed public statements acknowledging catastrophic AI risk. Instead, public communications focused on:
- US competitiveness with China as the primary AI challenge
- Regulation as burden on innovation
- Skepticism of "speculative" long-term risks

**Shift in Framing**: From "AI poses potential catastrophic risks" to "over-regulation of AI poses risks to US competitiveness"

## European Union Statements

### European Commission Officials

**President Ursula von der Leyen - AI Act Advocacy (2021-2024)**:

Throughout the AI Act's development, Commission President von der Leyen emphasized:
- AI regulation as necessary to protect fundamental rights
- Europe's role in setting global standards (the "Brussels Effect")
- Balance between innovation and safety
- Trustworthy AI as competitive advantage

**Commissioner Margrethe Vestager** (Executive VP for Digital):

As the lead Commission official on digital policy, Vestager stated:
> "The AI Act is not about slowing down innovation, it's about directing it in a direction that benefits people."

She repeatedly emphasized:
- Human oversight of AI systems
- Preventing discrimination and bias
- Accountability for AI developers
- The Act as model for global AI regulation

### EU AI Office Statements (2024-2025)

Officials from the newly established European AI Office have made public statements emphasizing:
- Focus on most powerful AI models (GPAI with systemic risk)
- Importance of transparency in AI development
- Cooperation with industry while maintaining regulatory authority
- Need for technical expertise in government

## United Nations and International Bodies

### UN Secretary-General António Guterres

**Multiple Statements on AI Risk (2023-2025)**:

Secretary-General Guterres has repeatedly called for international AI governance:

**September 2023 - UN General Assembly**:
> "Advances in AI could open new frontiers for humankind... But they could also be deeply destabilizing. We must urgently fill the governance gap with guardrails that are multilateral, inclusive and aligned with human rights."

**2024 - Launching UN AI Advisory Body**:
Guterres emphasized the need for:
- Global AI governance framework
- Ensuring AI serves humanity
- Preventing AI from being used for harmful purposes
- Bridging digital divide

**2025 - High-Level AI Forum**:
Continued to push for binding international measures, though with limited success in achieving concrete agreements.

### UN General Assembly Activities (2025)

**September 2025 - High-Level Week**:

**Nobel Prize Winners' Letter**:
Over 200 prominent politicians and scientists, including 10 Nobel Prize winners and many leading AI researchers, released an urgent call for binding international measures against dangerous AI uses.

**Maria Ressa** (Nobel Peace Prize laureate) announced the letter in her opening speech, stating:
> "We face a critical moment where the development of artificial intelligence could determine the future of humanity. We must act now, not after catastrophe has struck."

**Spanish Prime Minister Pedro Sánchez** headlined the launch of the UN's first diplomatic AI body, calling for:
- International cooperation on AI safety
- Balance between innovation and protection
- Inclusive governance involving Global South

### Shift in UN Approach (2024-2025)

**From Safety Summit to Action Summit**:
Instead of another AI Safety Summit like the UK's 2023 gathering, Paris hosted an "AI Action Summit" in early 2025. This marked a shift from risk-based framing to action-oriented perspective, reflecting:
- Impatience with slow progress on governance
- Desire to move from declarations to implementation
- Tension between precautionary and innovation-forward approaches

## Other Key National Statements

### China

**Minister Wu Zhaohui** (Ministry of Science and Technology):

At the Bletchley Summit, China's representative acknowledged AI risks and committed to cooperation. However, Chinese official statements have primarily emphasized:
- AI as tool for national development
- Sovereignty in AI governance (resistance to Western-dominated standards)
- Focus on concrete near-term risks (misinformation, social control) over speculative long-term risks

**Context**: China is pursuing aggressive AI development while also implementing extensive AI regulation focused on social stability and party control, not catastrophic risk prevention.

### France

**President Emmanuel Macron** has positioned France as a leader in European AI:

**Statements emphasizing**:
- Need for European "technological sovereignty"
- Open-source AI development as alternative to US dominance
- AI regulation through EU AI Act
- Balance between innovation and values

**AI Action Summit (2025)**: France's hosting of this summit reflected a more implementation-focused approach than the UK's 2023 safety-focused summit.

### Canada

**Prime Minister Justin Trudeau** and Innovation Minister **François-Philippe Champagne** have made statements supporting:
- International AI safety cooperation
- Canada's AI safety institute
- Balance between innovation and responsible development
- Particular focus on AI ethics and bias

### Australia

**Minister for Industry and Science Ed Husic** has emphasized:
- Australia's participation in international AI safety efforts
- Need for practical, implementable AI governance
- Focus on workforce impacts alongside safety concerns

### Japan

**Prime Minister Fumio Kishida** announced plans for Japan to host the Hiroshima AI Process, emphasizing:
- International cooperation on AI governance
- Japan's role in bridging different regulatory approaches
- Focus on both opportunities and risks

### India

India's approach has focused primarily on AI as development opportunity, with less emphasis on catastrophic risk. Statements from officials emphasize:
- AI for social good
- Ensuring AI benefits India's large population
- Participation in international discussions but skepticism of restrictions that might limit development

## Contrasting Framings Across Governments

### Three Broad Approaches Visible in Official Statements

**1. Risk-Forward Framing (UK 2023, Biden Administration 2023-2024)**:
- Explicit acknowledgment of catastrophic and potentially existential risks
- Emphasis on need for proactive governance before harms materialize
- Balancing innovation with safety as core message
- Government responsibility to protect public from AI risks

**2. Innovation-Forward Framing (Trump Administration 2025, some Asian nations)**:
- Primary emphasis on economic and strategic opportunities
- Concerns about over-regulation hampering competitiveness
- Focus on concrete near-term issues rather than speculative long-term risks
- Government role as enabling innovation, not constraining it

**3. Rights-and-Values Framing (EU)**:
- AI regulation as extension of fundamental rights protection
- Emphasis on human dignity, non-discrimination, transparency
- Less focus on catastrophic outcomes, more on ensuring AI aligns with European values
- Regulation as competitive advantage, not burden

### Geographic Patterns

**Western Europe**: Generally more willing to acknowledge risks and support regulation (though with variation)

**United States**: Highly politicized, with dramatic shift between administrations

**China**: Willing to regulate but focused on social stability and party control, not catastrophic risk prevention

**Global South**: Less prominent in these debates, often emphasizing development opportunities over risks

## Key Themes Across Political Statements (2023-2025)

### Theme 1: Acknowledgment of Risk is Not Universal

While the Bletchley Declaration represents broad acknowledgment, many officials remain skeptical of catastrophic AI risk concerns, viewing them as:
- Speculative and distant
- Distraction from concrete current harms
- Potentially motivated by incumbent companies seeking to limit competition

### Theme 2: Economic Competition Constrains Action

Nearly all statements emphasize the need to maintain competitiveness, particularly vis-à-vis:
- US-China AI race as dominant framing
- Europe seeking to avoid being left behind
- Other nations concerned about being excluded from AI benefits

This competitive dynamic makes coordination difficult and creates pressure to prioritize development speed over safety.

### Theme 3: Federal vs. International Governance Remains Unsettled

Disagreement persists about the appropriate level of governance:
- Should individual nations regulate AI?
- Should regional bodies (like the EU)?
- Is international coordination essential?
- What role for companies' self-governance?

### Theme 4: Short Political Timelines vs. Long AI Timelines

Political statements often focus on immediate concerns and actions, while AI development timelines (and potential catastrophic risks) extend over years or decades. This temporal mismatch creates challenges for sustained political attention.

### Theme 5: Expert Disagreement Enables Political Inaction

The visible disagreement among AI researchers about the nature and severity of risks gives political leaders cover to delay action, pending "more evidence" or "better understanding."

### Theme 6: Declarations Are Easier Than Implementation

The Bletchley Declaration and similar statements demonstrate that governments can agree on general principles. But translating these into specific policies has proven much more difficult, as evidenced by:
- Limited progress on binding international agreements
- Variation in national implementation
- Industry resistance to concrete requirements

## Absence and Silence: What Politicians Aren't Saying

### Limited Discussion of Existential Risk

Very few official government statements use the term "existential risk" or discuss potential human extinction from AI. Most stay at the level of "catastrophic harm" or "serious risks."

This may reflect:
- Political sensitivity of discussing potential human extinction
- Skepticism about x-risk among many officials
- Concern about being seen as alarmist
- Focus on more politically tractable near-term issues

### Minimal Discussion of Specific Scenarios

Political statements typically discuss AI risk in abstract terms, rarely engaging with specific scenarios such as:
- AI-enabled bioweapon creation
- Loss of control over AI systems
- Deliberate misuse by malicious actors
- Competitive dynamics leading to race to the bottom on safety

### Limited Engagement with Technical Details

Most political statements avoid technical specifics about:
- What makes an AI system dangerous
- How risks could be mitigated
- What safety measures are technically feasible
- How to evaluate AI capabilities and risks

This reflects both:
- Political communication norms (simple messages, broad themes)
- Limited technical expertise among most political leaders
- Genuine uncertainty about technical matters

### Rare Discussion of Governance Gaps

Few statements acknowledge structural challenges:
- How can governments with limited technical expertise effectively regulate AI?
- What happens if AI development outpaces governance capacity?
- How to handle AI developed in jurisdictions with weak governance?
- What if companies ignore regulations?

## Evolution of Political Framing (2023-2025)

### 2023: High-Water Mark for Risk Acknowledgment

The Bletchley Summit and Declaration represented peak political attention to catastrophic AI risk:
- Broad international consensus
- High-level engagement (heads of state, senior ministers)
- Media attention to AI safety concerns
- Political momentum behind governance efforts

### 2024: Implementation Challenges

Attempts to translate principles into policy ran into obstacles:
- California SB 1047 vetoed
- Limited progress on international binding agreements
- Industry resistance to specific requirements
- Technical challenges in defining and measuring risks

### 2025: Retrenchment and Fragmentation

Political support for proactive AI safety governance weakened:
- Trump administration rescinded Biden AI order
- Shift from safety focus to competitiveness focus
- Less emphasis on catastrophic risk in political statements
- Fragmentation of international approaches

### Trajectory Going Forward

As of February 2026, the political landscape appears characterized by:
- Continued EU implementation of AI Act
- US federal government opposition to AI safety regulation
- Stalled international coordination
- Continued statements of concern but limited binding action

## Comparative Analysis: How Governments Frame AI Risk

### United Kingdom (2023-2024)

**Risk Acknowledged**: Catastrophic harm from frontier AI
**Primary Concern**: Both capability and misuse risks
**Proposed Solution**: Voluntary cooperation + government testing/evaluation (AI Safety Institute)
**Key Value**: Positioning UK as global leader in AI safety
**Limitation**: Non-binding approach may lack teeth

### United States (Biden, 2023-2024)

**Risk Acknowledged**: Wide range including catastrophic risks
**Primary Concern**: Safety, security, discrimination, privacy
**Proposed Solution**: Executive action requiring reporting and safety measures
**Key Value**: Comprehensive approach across government
**Limitation**: Executive order easily reversed (as happened in 2025)

### United States (Trump, 2025-)

**Risk Acknowledged**: Minimal acknowledgment of catastrophic risk
**Primary Concern**: US falling behind China in AI development
**Proposed Solution**: Reduce regulation, accelerate development
**Key Value**: Innovation and competitiveness
**Limitation**: Potential safety risks from deregulation

### European Union

**Risk Acknowledged**: Risks to fundamental rights, some acknowledgment of serious harms
**Primary Concern**: Protecting European values and rights in AI deployment
**Proposed Solution**: Comprehensive binding regulation (AI Act)
**Key Value**: Rights-based approach, high standards
**Limitation**: May be seen as bureaucratic by industry; less focus on catastrophic risk specifically

### China

**Risk Acknowledged**: Risks to social stability and party control
**Primary Concern**: Maintaining sovereignty and stability
**Proposed Solution**: Extensive regulation focused on content and control
**Key Value**: Social stability and national development
**Limitation**: Authoritarian context limits transparency and international cooperation

## Implications for AI Governance

### What These Statements Reveal

**Positive Indicators**:
- International acknowledgment that AI poses significant risks
- High-level political attention to the issue
- Creation of new governance institutions (AI Safety Institutes, EU AI Office)
- Recognition that some form of governance is necessary

**Concerning Indicators**:
- Gap between declarations and binding action
- Political volatility (rapid reversal in US)
- Competitive dynamics undermining cooperation
- Limited engagement with existential risk specifically
- Industry influence on policy outcomes

### Barriers to Effective Governance Visible in Political Statements

1. **Knowledge Gap**: Most political leaders lack deep understanding of AI technology
2. **Time Horizon Mismatch**: Political incentives favor short-term thinking; AI risks are longer-term
3. **Regulatory Capture**: AI companies have significant influence over policy
4. **International Coordination**: Very difficult to achieve binding agreements
5. **Expert Disagreement**: Conflicting advice from AI researchers enables inaction
6. **Economic Pressure**: Fear of harming national competitiveness constrains action

## Key Figures Referenced

**Political Leaders**:
- Rishi Sunak (UK Prime Minister, 2023-2024)
- Joe Biden (US President, 2023-2024)
- Kamala Harris (US Vice President, 2023-2024)
- Donald Trump (US President, 2025-)
- Ursula von der Leyen (European Commission President)
- Emmanuel Macron (French President)
- António Guterres (UN Secretary-General)
- Pedro Sánchez (Spanish Prime Minister)
- Nancy Pelosi (Former US House Speaker)
- Gavin Newsom (California Governor)

**Ministers and Officials**:
- Margrethe Vestager (EU Commissioner)
- Wu Zhaohui (Chinese Science and Technology Minister)
- Ed Husic (Australian Industry Minister)
- François-Philippe Champagne (Canadian Innovation Minister)

## Sources Referenced

- UK Government: Bletchley Declaration (GOV.UK)
- US Government: Executive Order 14110 text and White House statements
- European Commission: AI Act communications and official statements
- United Nations: Secretary-General statements and General Assembly proceedings
- News coverage: Multiple outlets covering political statements and actions
- Carnegie Endowment for International Peace: Analysis of political dynamics
- Brookings Institution: Analysis of AI governance
