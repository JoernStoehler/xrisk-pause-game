---
title: "Years of Polling Show Overwhelming Voter Support for a Crackdown on AI"
author: "Public Citizen"
year: 2025
source_url: "https://www.citizen.org/article/years-of-polling-show-overwhelming-voter-support-for-a-crackdown-on-ai/"
source_format: html
downloaded: 2026-02-11
encrypted: false
notes: "Comprehensive analysis of multiple polling sources showing bipartisan voter support for AI regulation"
---

# Years of Polling Show Overwhelming Voter Support for a Crackdown on AI (2025)

## Foundational Consensus: AI Safety Rules

### Universal Support for Regulation

- **97% of Americans** believe AI safety should be subject to rules (Gallup/SCSP, Sept 2025)
- **80%** want government rules even if development slows
- Represents near-universal agreement on fundamental regulatory principle

## Specific Regulatory Support

### Safety Rules Over Development Speed

- **80%** want government rules for AI safety and data security even if development slows
- **Only 9%** prioritize rapid development over safety measures
- **Strongest bipartisan consensus** on any AI policy question

### Increased Regulation Demand

- **72%** want more AI industry regulation, up 15 points year-over-year (YouGov, Sept 2024)
- Indicates growing momentum for stronger oversight

## Competition Arguments Rejected

### "Race Against China" Framing Fails

- **75% of both Democrats and Republicans** reject racing ahead without regulation to compete with China (AI Policy Institute, July 2024)
- Bipartisan rejection of speed-first development narrative
- Indicates public prioritizes safety over geopolitical competition arguments

## Self-Regulation Rejected

### Industry Self-Regulation: Strongly Opposed

- **72%** reject tech industry self-regulation by 6-1 margin (YouGov/AIPI, Aug 2023)
- Overwhelming lack of confidence in industry-only oversight
- Demands government-led regulation

## Federal Regulatory Structure

### Support for Federal AI Agency

- **56%** would support a federal AI regulatory agency
- Indicates demand for specialized, dedicated regulatory authority

## Regulation vs. State Preemption

### Opposition to Federal Preemption of States

- **Nearly 60%** of likely voters oppose banning state-level AI regulation (Echelon Insights/Common Sense, May 2025)
- **81%** agree Congress should not ban states from protecting children's safety online
- Shows preference for multi-level regulatory approach, not federal-only

## Strength of Regulation Support

### "Heavily Regulated" Development Preference

- **73%** support "heavily regulated" AI development (Future of Life Institute, Oct 2025)
- **64%** want an immediate pause on advanced AI development
- **69%** believe government isn't regulating enough (Quinnipiac, April 2025)

### Regulation Satisfaction Gap

Current regulation perceived as insufficient across multiple polls—demand for stronger measures builds.

## Pre-Deployment Testing Requirements

### Mandatory Safety Measures Preferred

- **73%** support mandatory safety measures and pre-deployment government approval (AIPI/Transformer, Jan 2025)
- Indicates preference for pharmaceutical-style regulatory model
- Want verification of safety before market release

## Deepfake and Misinformation Regulation

### Deepfake Disclosure Requirements

- **87%** favor deepfake disclosure requirements in political ads (Tech Policy Press/YouGov, Aug 2024)
- Highest support for specific AI regulation proposal measured
- Indicates democratic integrity as paramount concern

### Misinformation and Fraud Concerns

- **88%** want government rules on spread of false information (Gallup)
- **82%** want protection from personal data privacy violations
- High prioritization of harmful AI applications

## Job Displacement and Economic Concerns

### Worker Protection Support

- **68%** say government is responsible for addressing job displacement from AI
- **69%** support policies protecting workers from displacement (California survey)
- Indicates demand for economic safety net alongside technological development

## International Coordination

### Multilateral Development Preference

- **42%** prefer collaboration with broad coalition of allies
- **19%** support partnerships with smaller ally groups
- **Only 14%** prefer independent U.S. development

Public rejects nationalist AI development approach in favor of international cooperation.

## Data Privacy and Security

### Privacy as Top Regulatory Priority

- **72%** concerned about privacy intrusion by AI (California)
- **82%** want protection from personal data privacy violations (Gallup)
- Personal privacy protection is highest priority for many voters

## Responsible Development Timelines

### Pause on Advanced AI

- **64%** want immediate pause on advanced AI development
- **49%** expect superhuman AI within 5 years
- Indicates desire to slow development timelines

### Safety Testing Timelines

- **64%** want pharmaceutical-style safety testing before advanced AI deployment
- Willing to accept years-long approval timelines for safety verification

## Political Party Alignment

### Bipartisan Consensus Areas

Republicans and Democrats align on:
- **AI safety rules necessity**: 79-88% support
- **Deepfake regulation**: Strong bipartisan agreement
- **Worker protections**: Broad support across parties
- **Skepticism of self-regulation**: 72% rejection across both parties

### Partisan Differences

Disagreement emerges on:
- **Regulation stringency**: Democrats favor stronger
- **International cooperation**: Democrats more supportive
- **Government testing role**: Republicans prefer industry/independent
- **Speed of development**: Republicans less willing to accept constraints

## Media Coverage Influence

### Framing Effects

Public opinion polls reveal different responses to:
- **"Race" framing**: Reduces support for regulation
- **"Safety" framing**: Increases regulation support
- **"Jobs" framing**: Strong concern mobilizer
- **"Misinformation" framing**: Highest concern mobilizer

## Public Understanding and Knowledge

### AI Knowledge Levels

- **64%** report being at least somewhat knowledgeable
- Knowledge correlates with regulatory sophistication
- Misconceptions exist but don't drive down regulation demand

### Concern Despite Uncertainty

- Even with limited knowledge, public demands regulation
- Suggests precautionary principle is operative in public reasoning

## Generational Differences

### Younger Voters

- More familiar with AI applications
- Still support safety regulations at high rates
- Show different risk perceptions (more acceptance of AI generally)

### Older Voters

- Less familiar with AI specifics
- Support regulation at similarly high rates
- Concerns focus on different impacts

## Conclusion: Policy Mandate

### Clear Public Mandate for Action

Multiple polling sources from 2023-2025 show:
- **97%** support for regulation foundation
- **80%** accept development slowdown for safety
- **72%** want stronger regulation than current
- **73%** support heavy regulation model
- **56%** would support new federal agency

### Weakness: Implementation Skepticism

While support for regulation is overwhelming, public doubts government's regulatory capacity:
- **62%** lack confidence in government regulation effectiveness
- **68%** believe regulators lack technical understanding
- Indicates need for independent oversight mechanisms

## Relevance to AI CEO Game

1. **Strong Regulatory Pressure Coming**: Public mandate for stricter rules will drive political response
2. **Speed-First Strategy is Politically Toxic**: "Race" framing will backfire; need "responsible development" narrative
3. **Worker Concerns Drive Politics**: Job displacement anxiety is motivator for regulation demand
4. **International Cooperation**: Political pressure will push toward multilateral approaches
5. **Safety Testing Becomes Expectation**: Pre-deployment testing frameworks will be required
6. **State-Level Regulation**: Federal regulation insufficient; state patchwork will emerge
7. **Deepfake Concerns**: Election integrity fears create urgent regulation demand
8. **Company Credibility Crisis**: Tech industry self-regulation has 0% support—need independent oversight credibility
